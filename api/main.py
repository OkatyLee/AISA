from fastapi import FastAPI, HTTPException, Depends
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi import Request
from fastapi.middleware.cors import CORSMiddleware
import hashlib
import hmac
import json
import urllib.parse
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from database import SQLDatabase as db
from config.config import load_config
import logging
from utils import setup_logger

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
from services.search import SearchService
from services.search.arxiv_service import ArxivSearcher
from services.search.semantic_scholar_service import SemanticScholarSearcher
from services.search.ieee_service import IEEESearcher
from services.search.ncbi_service import NCBISearcher
from services.utils.paper import Paper
from nlp.intent_classifier import RuleBasedIntentClassifier
from nlp.entity_classifier import RuleBasedEntityExtractor
from services.utils.search_utils import SearchUtils
import asyncio

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = setup_logger(name="api_logger", log_file="logs/api.log", level=logging.DEBUG)

app = FastAPI(title="Scientific Assistant API", version="1.0.0")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
config = load_config()

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Mini App
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://t.me", "https://web.telegram.org"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –∏ —à–∞–±–ª–æ–Ω—ã
app.mount("/static", StaticFiles(directory="webapp/static"), name="static")
templates = Jinja2Templates(directory="webapp/templates")

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class PaperTags(BaseModel):
    new_tags: str

class UserLibrary(BaseModel):
    papers: List[Dict[str, Any]]
    total_count: int
    user_id: int

class TelegramInitData(BaseModel):
    user_id: int
    username: Optional[str] = None
    first_name: Optional[str] = None
    last_name: Optional[str] = None

class SearchRequest(BaseModel):
    query: str
    filters: Optional[Dict[str, Any]] = {}
    limit: int = 10
    source: Optional[str] = None  # arxiv, ieee, ncbi, semantic_scholar

class RecommendationRequest(BaseModel):
    paper_ids: List[str]
    limit: int = 10

class ChatRequest(BaseModel):
    message: str
    context: Optional[List[Dict[str, Any]]] = []

def validate_telegram_init_data(init_data: str) -> Optional[Dict[str, Any]]:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö initData –æ—Ç Telegram
    
    Args:
        init_data: –°—Ç—Ä–æ–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç Telegram
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –ü–∞—Ä—Å–∏–º query string
        parsed_data = urllib.parse.parse_qs(init_data)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º hash –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        received_hash = parsed_data.get('hash', [None])[0]
        if not received_hash:
            logger.warning("–ù–µ—Ç hash –≤ initData")
            return None
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–ø–∏—Å–∏
        auth_data = []
        for key in sorted(parsed_data.keys()):
            if key != 'hash':
                auth_data.append(f"{key}={parsed_data[key][0]}")
        
        auth_string = '\n'.join(auth_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–ø–∏—Å—å
        secret_key = hmac.new(
            "WebAppData".encode(), 
            config.BOT_TOKEN.encode(), 
            hashlib.sha256
        ).digest()
        
        calculated_hash = hmac.new(
            secret_key,
            auth_string.encode(),
            hashlib.sha256
        ).hexdigest()
        
        if not hmac.compare_digest(received_hash, calculated_hash):
            logger.warning("–ù–µ–≤–µ—Ä–Ω–∞—è –ø–æ–¥–ø–∏—Å—å initData")
            return None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_data = parsed_data.get('user', [None])[0]
        if user_data:
            user_info = json.loads(user_data)
            return {
                'user_id': user_info.get('id'),
                'username': user_info.get('username'),
                'first_name': user_info.get('first_name'),
                'last_name': user_info.get('last_name')
            }
        
        return None
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ initData: {e}")
        return None

def get_current_user(request: Request) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ initData"""
    init_data = request.headers.get('X-Telegram-Init-Data')
    if not init_data:
        init_data = request.query_params.get('initData')
    
    if not init_data:
        raise HTTPException(status_code=401, detail="–ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
    
    user_data = validate_telegram_init_data(init_data)
    if not user_data:
        raise HTTPException(status_code=401, detail="–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
    
    return user_data

@app.get("/", response_class=HTMLResponse)
async def mini_app_root(request: Request):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ Mini App"""
    return templates.TemplateResponse("library.html", {"request": request})

@app.get("/api/v1/user/info")
async def get_user_info(current_user: Dict[str, Any] = Depends(get_current_user)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    return {
        "user_id": current_user["user_id"],
        "username": current_user.get("username"),
        "first_name": current_user.get("first_name"),
        "last_name": current_user.get("last_name")
    }

@app.get("/api/v1/library", response_model=UserLibrary)
async def get_user_library(
    page: int = 1,
    per_page: int = 10,
    search: Optional[str] = None,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ –ø–æ–∏—Å–∫–æ–º
    
    Args:
        page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞—á–∏–Ω–∞—è —Å 1)
        per_page: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        search: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        current_user: –î–∞–Ω–Ω—ã–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
    Returns:
        UserLibrary: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ó–∞–ø—Ä–æ—Å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}, –ø–æ–∏—Å–∫: '{search}'")
        
        if search:
            all_papers = await db.search_in_library(user_id, search)
        else:
            all_papers = await db.get_user_library(user_id)
        
        total_count = len(all_papers)
        
        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        start_index = (page - 1) * per_page
        end_index = start_index + per_page
        papers = all_papers[start_index:end_index]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        formatted_papers = []
        for paper in papers:
            formatted_papers.append({
                "id": paper.get("id"),
                "title": paper.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "authors": paper.get("authors", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∞–≤—Ç–æ—Ä—ã"),
                "abstract": paper.get("abstract", "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"),
                "url": paper.get("url", ""),
                "publication_date": paper.get("publication_date", ""),
                "saved_at": paper.get("saved_at", ""),
                "tags": paper.get("tags", []),
                "external_id": paper.get("external_id", ""),
                "source": paper.get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫"),
                
            })
        
        return UserLibrary(
            papers=formatted_papers,
            total_count=total_count,
            user_id=user_id
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏")

@app.delete("/api/v1/library/{paper_id}")
async def delete_paper_from_library(
    paper_id: str,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –ø—ã—Ç–∞–µ—Ç—Å—è —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ç—å—é {paper_id}")
        
        success = await db.delete_paper(user_id, paper_id)
        
        if success:
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–∏–ª —Å—Ç–∞—Ç—å—é {paper_id}")
            return {"message": "–°—Ç–∞—Ç—å—è —É–¥–∞–ª–µ–Ω–∞", "success": True}
        else:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å—é {paper_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            raise HTTPException(status_code=404, detail="–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏")

@app.get("/api/v1/stats")
async def get_library_stats(current_user: Dict[str, Any] = Depends(get_current_user)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        user_id = current_user["user_id"]
        papers = await db.get_user_library(user_id)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories_count = {}
        for paper in papers:
            if paper.get("categories"):
                for category in paper["categories"]:
                    category = category.strip()
                    categories_count[category] = categories_count.get(category, 0) + 1
        
        return {
            "total_papers": len(papers),
            "categories_distribution": categories_count,
            "user_id": user_id
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

@app.post("/api/v1/library/{paper_id}/tags")
async def edit_paper_tags(
    paper_id: str,
    tags_data: PaperTags,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ —Å—Ç–∞—Ç—å–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –ø—ã—Ç–∞–µ—Ç—Å—è –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–≥–∏ —Å—Ç–∞—Ç—å–∏ {paper_id} –Ω–∞ '{tags_data.new_tags}'")
        paper_id = paper_id.replace('BACKSLASH', '/')
        
        success = await db.edit_paper_tags(user_id, paper_id, tags_data.new_tags)
        
        if success:
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–∏–ª —Ç–µ–≥–∏ —Å—Ç–∞—Ç—å–∏ {paper_id}")
            return {"message": "–¢–µ–≥–∏ —Å—Ç–∞—Ç—å–∏ –∏–∑–º–µ–Ω–µ–Ω—ã", "success": True}
        else:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å—é {paper_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            raise HTTPException(status_code=404, detail="–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–≥–æ–≤ —Å—Ç–∞—Ç—å–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–≥–æ–≤ —Å—Ç–∞—Ç—å–∏")

# –ù–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

@app.post("/api/v1/search")
async def search_papers(
    search_request: SearchRequest,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    –ü–æ–∏—Å–∫ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π —á–µ—Ä–µ–∑ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    """
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –∏—â–µ—Ç: '{search_request.query}'")
        
        results = []
        
        if search_request.source == "arxiv":
            async with ArxivSearcher() as searcher:
                papers = await searcher.search_papers(
                    search_request.query, 
                    limit=search_request.limit,
                    filters=search_request.filters
                )
                results = papers
        elif search_request.source == "ieee":
            async with IEEESearcher() as searcher:
                papers = await searcher.search_papers(
                    search_request.query,
                    limit=search_request.limit,
                    filters=search_request.filters
                )
                results = papers
        elif search_request.source == "ncbi":
            async with NCBISearcher() as searcher:
                papers = await searcher.search_papers(
                    search_request.query,
                    limit=search_request.limit,
                    filters=search_request.filters
                )
                results = papers
        elif search_request.source == "semantic_scholar":
            async with SemanticScholarSearcher() as searcher:
                papers = await searcher.search_papers(
                    search_request.query,
                    limit=search_request.limit,
                    filters=search_request.filters
                )
                results = papers
        else:
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            async with SearchService() as search_service:
                search_results = await search_service.search_papers(
                    search_request.query,
                    limit=search_request.limit,
                    filters=search_request.filters
                )
                results = search_service.aggregate_results(search_results, search_request.query)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        saved_urls = await SearchUtils._get_user_saved_urls(user_id)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        formatted_results = []
        for paper in results:
            paper_dict = paper.to_dict() if hasattr(paper, 'to_dict') else paper.__dict__
            paper_dict['is_saved'] = paper_dict.get('url', '') in saved_urls
            formatted_results.append(paper_dict)
        
        return {
            "papers": formatted_results,
            "total_count": len(formatted_results),
            "query": search_request.query,
            "source": search_request.source or "all"
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞")

@app.post("/api/v1/recommendations")
async def get_recommendations(
    recommendation_request: RecommendationRequest,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    """
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        
        if recommendation_request.paper_ids:
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö ID
            papers = [Paper(external_id=paper_id) for paper_id in recommendation_request.paper_ids]
            async with SemanticScholarSearcher() as searcher:
                recommendations = await searcher.get_recommendations_for_multiple_papers(
                    papers, 
                    recommendation_request.limit
                )
        else:
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_papers = await db.get_user_library(user_id)
            if not user_papers:
                return {"papers": [], "total_count": 0, "message": "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞"}
            
            papers = [Paper(**paper) for paper in user_papers[:10]]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç–∞—Ç–µ–π
            async with SemanticScholarSearcher() as searcher:
                recommendations = await searcher.get_recommendations_for_multiple_papers(
                    papers, 
                    recommendation_request.limit
                )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        saved_urls = await SearchUtils._get_user_saved_urls(user_id)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        formatted_results = []
        for paper in recommendations:
            paper_dict = paper.to_dict() if hasattr(paper, 'to_dict') else paper.__dict__
            paper_dict['is_saved'] = paper_dict.get('url', '') in saved_urls
            formatted_results.append(paper_dict)
        
        return {
            "papers": formatted_results,
            "total_count": len(formatted_results)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")

@app.post("/api/v1/chat")
async def chat_with_assistant(
    chat_request: ChatRequest,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    –ß–∞—Ç —Å AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
    
    TODO: –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π. –ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å –ª–æ–≥–∏–∫—É –æ–±—â–µ–Ω–∏—è.
    """
    try:
        user_id = current_user["user_id"]
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –æ—Ç–ø—Ä–∞–≤–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ: '{chat_request.message}'")
        
        response = {
            "intent": None,
            "confidence": None,
            "entities": None,
            "response_text": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Ñ—É–Ω–∫—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.",
            "action": None,
            "data": {}
        }
        
        return ''
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π
        intent_classifier = RuleBasedIntentClassifier()
        entity_extractor = RuleBasedEntityExtractor()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
        intent_result = intent_classifier.classify(chat_request.message)
        entities = await entity_extractor.extract(chat_request.message, None)

        response = {
            "intent": intent_result.intent.value,
            "confidence": intent_result.confidence,
            "entities": entities,
            "response_text": "",
            "action": None,
            "data": {}
        }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        if intent_result.intent.value == "search":
            query = entities.get("query", chat_request.message)
            response["action"] = "search"
            response["data"] = {
                "query": query,
                "filters": {
                    "author": entities.get("author"),
                    "year": entities.get("year"),
                    "journal": entities.get("journal")
                }
            }
            response["response_text"] = f"–ò—â—É —Å—Ç–∞—Ç—å–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}"
            
        elif intent_result.intent.value == "list_saved":
            response["action"] = "show_library"
            response["response_text"] = "–ü–æ–∫–∞–∑—ã–≤–∞—é –≤–∞—à—É –±–∏–±–ª–∏–æ—Ç–µ–∫—É —Å—Ç–∞—Ç–µ–π"
            
        elif intent_result.intent.value == "get_summary":
            urls = entities.get("urls", [])
            if urls:
                response["action"] = "summarize"
                response["data"] = {"urls": urls}
                response["response_text"] = f"–ì–æ—Ç–æ–≤–ª—é –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏: {urls[0]}"
            else:
                response["response_text"] = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞—Ç—å—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"
                
        elif intent_result.intent.value == "help":
            response["response_text"] = (
                "–Ø –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º:\n"
                "üîç –ò—Å–∫–∞—Ç—å –Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏\n"
                "üìö –£–ø—Ä–∞–≤–ª—è—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π\n"
                "üéØ –ü–æ–ª—É—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
                "üìÑ –°–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–∑—é–º–µ —Å—Ç–∞—Ç–µ–π\n\n"
                "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç!"
            )
            
        elif intent_result.intent.value == "greeting":
            response["response_text"] = (
                "–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –Ω–∞—É—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. "
                "–Ø –ø–æ–º–æ–≥—É –Ω–∞–π—Ç–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏. "
                "–ß—Ç–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?"
            )
            
        else:
            response["response_text"] = (
                "–Ø –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª –≤–∞—à –∑–∞–ø—Ä–æ—Å. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–ø—Ä–æ—Å–∏—Ç—å –æ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π, –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏–ª–∏ –ø–æ–º–æ—â–∏."
            )
        
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è")

@app.post("/api/v1/library/save")
async def save_paper_to_library(
    paper: Dict[str, Any],
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É"""
    try:
        user_id = current_user["user_id"]
        paper = paper.get('paper') or paper
        logger.debug(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –ø—ã—Ç–∞–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç—å—é: {paper}")
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—å—é {paper['external_id']}")

        success = await db.save_paper(user_id, paper)
        if success:
            return {"message": "–°—Ç–∞—Ç—å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞", "success": True}
        else:
            return {"message": "–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏", "success": False}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
